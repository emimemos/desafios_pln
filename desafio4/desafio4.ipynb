{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6eebc7c-634f-4665-8826-0e4e96af7003",
   "metadata": {},
   "source": [
    "**Carga de Datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7566db77-d7e9-4ee8-bb18-0acdbd6b9640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de pares de conversación cargados: 10000\n",
      "Tamaño del vocabulario: 11059\n",
      "Datos guardados en 'datos_entrenamiento.npz'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "import requests\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "import gensim.downloader as api\n",
    "\n",
    "# 1. Descargar el Cornell Movie Dialogues Dataset\n",
    "dataset_url = \"http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\"\n",
    "dataset_path = \"cornell_movie_dialogs_corpus.zip\"\n",
    "extracted_folder = \"cornell_movie_dialogs_corpus\"\n",
    "\n",
    "if not os.path.exists(extracted_folder):\n",
    "    print(\"Descargando el dataset...\")\n",
    "    response = requests.get(dataset_url)\n",
    "    with open(dataset_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(\"Dataset descargado. Extrayendo...\")\n",
    "    with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extracted_folder)\n",
    "    print(\"Extracción completada.\")\n",
    "\n",
    "# 2. Función para procesar datos\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "    return text.strip()\n",
    "\n",
    "def load_and_process_data(filepath, max_pairs=20000):\n",
    "    input_sentences = []\n",
    "    output_sentences = []\n",
    "    with open(filepath, \"r\", encoding=\"iso-8859-1\") as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(\" +++$+++ \")\n",
    "            if len(parts) >= 2:\n",
    "                question = clean_text(parts[0])\n",
    "                answer = clean_text(parts[1])\n",
    "                if len(question.split()) > 3 and len(answer.split()) > 3:  # Filtra frases muy cortas\n",
    "                    input_sentences.append(question)\n",
    "                    output_sentences.append(f\"<sos> {answer} <eos>\")\n",
    "            if len(input_sentences) >= max_pairs:\n",
    "                break\n",
    "    return input_sentences, output_sentences\n",
    "\n",
    "\n",
    "# 3. Procesar los datos\n",
    "lines_file = os.path.join(extracted_folder, \"movie_lines.txt\")\n",
    "conversations_file = os.path.join(extracted_folder, \"movie_conversations.txt\")\n",
    "\n",
    "input_sentences, output_sentences = load_and_process_cornell_data(lines_file, conversations_file, max_pairs=10000)\n",
    "print(\"Número de pares de conversación cargados:\", len(input_sentences))\n",
    "\n",
    "# 4. Tokenización y padding\n",
    "MAX_VOCAB_SIZE = 8000\n",
    "MAX_LEN = 10\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters=\"\", oov_token=\"<unk>\")\n",
    "tokenizer.fit_on_texts(input_sentences + output_sentences)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Tamaño del vocabulario:\", vocab_size)\n",
    "\n",
    "encoder_input_seq = pad_sequences(tokenizer.texts_to_sequences(input_sentences), maxlen=MAX_LEN, padding='pre')\n",
    "decoder_input_seq = pad_sequences(tokenizer.texts_to_sequences(output_sentences), maxlen=MAX_LEN, padding='post')\n",
    "\n",
    "# Targets\n",
    "decoder_target_seq = np.zeros_like(decoder_input_seq)\n",
    "decoder_target_seq[:, :-1] = decoder_input_seq[:, 1:]\n",
    "\n",
    "# Guardar los datos\n",
    "np.savez(\"datos_entrenamiento.npz\", \n",
    "         encoder_input_seq=encoder_input_seq, \n",
    "         decoder_input_seq=decoder_input_seq, \n",
    "         decoder_target_seq=decoder_target_seq, \n",
    "         vocab_size=vocab_size, \n",
    "         tokenizer_word_index=tokenizer.word_index)\n",
    "print(\"Datos guardados en 'datos_entrenamiento.npz'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802801ca-0275-410b-9077-e1ef0fede69b",
   "metadata": {},
   "source": [
    "**Entrenamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "455f1e86-a8d3-43c4-9bdd-a6193ede6b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando embeddings FastText...\n",
      "Embeddings cargados.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_18\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_18\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_15      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_15        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,317,700</span> │ input_layer_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_16        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,317,700</span> │ input_layer_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">570,368</span> │ embedding_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">570,368</span> │ embedding_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ lstm_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],    │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ lstm_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11059</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,842,163</span> │ lstm_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_15      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_15        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │  \u001b[38;5;34m3,317,700\u001b[0m │ input_layer_14[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_16        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │  \u001b[38;5;34m3,317,700\u001b[0m │ input_layer_15[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_14 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │    \u001b[38;5;34m570,368\u001b[0m │ embedding_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_15 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m570,368\u001b[0m │ embedding_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ lstm_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],    │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ lstm_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m11059\u001b[0m) │  \u001b[38;5;34m2,842,163\u001b[0m │ lstm_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,618,299</span> (40.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,618,299\u001b[0m (40.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,982,899</span> (15.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,982,899\u001b[0m (15.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,635,400</span> (25.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m6,635,400\u001b[0m (25.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando el entrenamiento...\n",
      "Epoch 1/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 218ms/step - accuracy: 0.3135 - loss: 6.1356 - val_accuracy: 0.3007 - val_loss: 4.6639\n",
      "Epoch 2/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 208ms/step - accuracy: 0.3617 - loss: 4.1651 - val_accuracy: 0.3871 - val_loss: 4.3959\n",
      "Epoch 3/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 209ms/step - accuracy: 0.4197 - loss: 3.9122 - val_accuracy: 0.4031 - val_loss: 4.2893\n",
      "Epoch 4/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 210ms/step - accuracy: 0.4335 - loss: 3.7891 - val_accuracy: 0.4078 - val_loss: 4.2223\n",
      "Epoch 5/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 207ms/step - accuracy: 0.4390 - loss: 3.7075 - val_accuracy: 0.4120 - val_loss: 4.1800\n",
      "Epoch 6/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 212ms/step - accuracy: 0.4468 - loss: 3.6174 - val_accuracy: 0.4138 - val_loss: 4.1622\n",
      "Epoch 7/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 209ms/step - accuracy: 0.4465 - loss: 3.5802 - val_accuracy: 0.4163 - val_loss: 4.1521\n",
      "Epoch 8/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 210ms/step - accuracy: 0.4514 - loss: 3.5205 - val_accuracy: 0.4192 - val_loss: 4.1240\n",
      "Epoch 9/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 207ms/step - accuracy: 0.4526 - loss: 3.4867 - val_accuracy: 0.4221 - val_loss: 4.1056\n",
      "Epoch 10/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 207ms/step - accuracy: 0.4582 - loss: 3.4185 - val_accuracy: 0.4241 - val_loss: 4.0902\n",
      "Epoch 11/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 208ms/step - accuracy: 0.4569 - loss: 3.3846 - val_accuracy: 0.4269 - val_loss: 4.0782\n",
      "Epoch 12/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 208ms/step - accuracy: 0.4591 - loss: 3.3460 - val_accuracy: 0.4276 - val_loss: 4.0761\n",
      "Epoch 13/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 203ms/step - accuracy: 0.4631 - loss: 3.2896 - val_accuracy: 0.4296 - val_loss: 4.0751\n",
      "Epoch 14/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 201ms/step - accuracy: 0.4643 - loss: 3.2631 - val_accuracy: 0.4305 - val_loss: 4.0759\n",
      "Epoch 15/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 206ms/step - accuracy: 0.4631 - loss: 3.2301 - val_accuracy: 0.4336 - val_loss: 4.0643\n",
      "Epoch 16/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 205ms/step - accuracy: 0.4657 - loss: 3.1909 - val_accuracy: 0.4340 - val_loss: 4.0602\n",
      "Epoch 17/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 210ms/step - accuracy: 0.4633 - loss: 3.1793 - val_accuracy: 0.4352 - val_loss: 4.0706\n",
      "Epoch 18/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 209ms/step - accuracy: 0.4707 - loss: 3.1244 - val_accuracy: 0.4356 - val_loss: 4.0695\n",
      "Epoch 19/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 210ms/step - accuracy: 0.4692 - loss: 3.0916 - val_accuracy: 0.4345 - val_loss: 4.0755\n",
      "Epoch 20/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 209ms/step - accuracy: 0.4670 - loss: 3.0971 - val_accuracy: 0.4360 - val_loss: 4.0826\n",
      "Epoch 21/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 206ms/step - accuracy: 0.4768 - loss: 3.0023 - val_accuracy: 0.4369 - val_loss: 4.0736\n",
      "Epoch 22/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 212ms/step - accuracy: 0.4695 - loss: 3.0320 - val_accuracy: 0.4365 - val_loss: 4.0870\n",
      "Epoch 23/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 211ms/step - accuracy: 0.4711 - loss: 3.0025 - val_accuracy: 0.4391 - val_loss: 4.0906\n",
      "Epoch 24/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 211ms/step - accuracy: 0.4713 - loss: 2.9698 - val_accuracy: 0.4389 - val_loss: 4.0912\n",
      "Epoch 25/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 215ms/step - accuracy: 0.4793 - loss: 2.9251 - val_accuracy: 0.4401 - val_loss: 4.0963\n",
      "Epoch 26/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 210ms/step - accuracy: 0.4761 - loss: 2.9093 - val_accuracy: 0.4392 - val_loss: 4.1167\n",
      "Epoch 27/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 215ms/step - accuracy: 0.4759 - loss: 2.8853 - val_accuracy: 0.4388 - val_loss: 4.1167\n",
      "Epoch 28/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 214ms/step - accuracy: 0.4744 - loss: 2.8739 - val_accuracy: 0.4406 - val_loss: 4.1180\n",
      "Epoch 29/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 211ms/step - accuracy: 0.4706 - loss: 2.8766 - val_accuracy: 0.4398 - val_loss: 4.1275\n",
      "Epoch 30/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 212ms/step - accuracy: 0.4748 - loss: 2.8390 - val_accuracy: 0.4404 - val_loss: 4.1394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento finalizado.\n",
      "Modelo guardado como 'seq2seq_qa_model.h5'.\n"
     ]
    }
   ],
   "source": [
    "# entrenamiento.py\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Cargar los datos\n",
    "data = np.load(\"datos_entrenamiento.npz\", allow_pickle=True)\n",
    "encoder_input_seq = data[\"encoder_input_seq\"]\n",
    "decoder_input_seq = data[\"decoder_input_seq\"]\n",
    "decoder_target_seq = data[\"decoder_target_seq\"]\n",
    "vocab_size = int(data[\"vocab_size\"])\n",
    "tokenizer_word_index = data[\"tokenizer_word_index\"].item()\n",
    "\n",
    "MAX_LEN = encoder_input_seq.shape[1]\n",
    "embedding_dim = 300\n",
    "n_units = 256\n",
    "\n",
    "# Embeddings FastText\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "print(\"Cargando embeddings FastText...\")\n",
    "fasttext_model = api.load(\"fasttext-wiki-news-subwords-300\")\n",
    "for word, idx in tokenizer_word_index.items():\n",
    "    if word in fasttext_model:\n",
    "        embedding_matrix[idx] = fasttext_model[word]\n",
    "print(\"Embeddings cargados.\")\n",
    "\n",
    "dropout_rate = 0.4\n",
    "\n",
    "encoder_inputs = Input(shape=(MAX_LEN,))\n",
    "encoder_embedding = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable=False)(encoder_inputs)\n",
    "encoder_outputs, state_h, state_c = LSTM(n_units, return_state=True, dropout=dropout_rate)(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(MAX_LEN,))\n",
    "decoder_embedding = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable=False)(decoder_inputs)\n",
    "decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True, dropout=dropout_rate)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = Dense(vocab_size, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "# Entrenar el modelo\n",
    "print(\"Iniciando el entrenamiento...\")\n",
    "model.fit(\n",
    "    [encoder_input_seq, decoder_input_seq],\n",
    "    np.expand_dims(decoder_target_seq, -1),\n",
    "    batch_size=64,\n",
    "    epochs=30,\n",
    "    validation_split=0.2\n",
    ")\n",
    "print(\"Entrenamiento finalizado.\")\n",
    "model.save(\"seq2seq_qa_model.h5\")\n",
    "print(\"Modelo guardado como 'seq2seq_qa_model.h5'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0318edc-a6df-4876-b438-2d29c6ae6c30",
   "metadata": {},
   "source": [
    "**Inferencia**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c8531e5-88ca-4d65-a21f-171e9abe573f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado.\n"
     ]
    }
   ],
   "source": [
    "# inferencia.py\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "# Cargar datos\n",
    "data = np.load(\"datos_entrenamiento.npz\", allow_pickle=True)\n",
    "tokenizer_word_index = data[\"tokenizer_word_index\"].item()\n",
    "vocab_size = int(data[\"vocab_size\"])\n",
    "MAX_LEN = 10\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "model = load_model(\"seq2seq_qa_model.h5\")\n",
    "print(\"Modelo cargado.\")\n",
    "\n",
    "# Configurar el modelo para inferencia\n",
    "encoder_inputs = model.input[0]\n",
    "encoder_embedding = model.layers[2]\n",
    "encoder_lstm = model.layers[4]\n",
    "encoder_model = Model(encoder_inputs, encoder_lstm.output[1:])\n",
    "\n",
    "decoder_inputs = model.input[1]\n",
    "decoder_embedding = model.layers[3]\n",
    "decoder_lstm = model.layers[5]\n",
    "decoder_dense = model.layers[6]\n",
    "\n",
    "state_input_h = Input(shape=(256,))\n",
    "state_input_c = Input(shape=(256,))\n",
    "decoder_states_inputs = [state_input_h, state_input_c]\n",
    "decoder_embedding_input = decoder_embedding(decoder_inputs)\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_embedding_input, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Generar respuestas\n",
    "tokenizer_index_word = {v: k for k, v in tokenizer_word_index.items()}\n",
    "def generate_response(input_text):\n",
    "    input_seq = pad_sequences(tokenizer.texts_to_sequences([input_text]), maxlen=MAX_LEN)\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = tokenizer_word_index['<sos>']\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        sampled_idx = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = tokenizer_index_word.get(sampled_idx, \"\")\n",
    "\n",
    "        if sampled_word == \"<eos>\" or len(decoded_sentence.split()) >= MAX_LEN:\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence += \" \" + sampled_word\n",
    "\n",
    "        target_seq[0, 0] = sampled_idx\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09f4d40b-6ff8-4385-ab99-c88438224cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "what's your name? QA Bot:  i dont know\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "do you like movies? QA Bot:  i dont know\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Do you read? QA Bot:  i dont know\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Do you have any pet? QA Bot:  i dont know\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Where are you from? QA Bot:  i dont know\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prueba del modelo\n",
    "print(\"what's your name? QA Bot: \", generate_response(\"what's your name\"))\n",
    "print(\"do you like movies? QA Bot: \", generate_response(\"do you like movies\"))\n",
    "print(\"Do you read? QA Bot: \", generate_response(\"Do you read?\"))\n",
    "print(\"Do you have any pet? QA Bot: \", generate_response(\"Do you have any pet?\"))\n",
    "print(\"Where are you from? QA Bot: \", generate_response(\"Where are you from?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d6b1c0-24b4-450a-b233-f35b0829b7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
